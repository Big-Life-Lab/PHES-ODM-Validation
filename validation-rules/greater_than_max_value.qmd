# greater_than_max_value

```{python}
import sys
sys.path.append("../src")

# Some pretty printing functions
from odm_validation.doc_utils import (
    pprint_dict_list,
    pprint_csv_file,
    pprint_json_file,
    pprint_yaml_file,
)

assets_path = "../assets/validation-rules/greater-than-max-value"
```

This rule ensure that columns values are not greater than a defined maximum value. Currently, this rule only supports columns whose data type is float or integer i.e. numbers. As an example, consider the `geoLat` column and `geoLong` column in the `sites` table. For the purpose of explaining this rule we'll assume the `geoLat` column is an `integer` with a maximum value of 90 and the `geoLong` column is a `float` with a maximum value of 90.15. The following dataset snippet would fail validation,

```{python}
# Using a yaml file here since in a CSV file every value is by default a string
pprint_yaml_file(assets_path + "/invalid-dataset-1.yml")
```

whereas the following dataset snippet would pass validation,

```{python}
# Using a yaml file here since in a CSV file every value is by default a string
pprint_yaml_file(assets_path + "/valid-dataset-1.yml")
```

If the value to be validated is not a number but can be coerced into one, then a warning is given. Whether the coerced value is valid or not, a warning should reported informing the user of the mismatched type. For example the following dataset would fail validation with an error and a warning,

```{python}
pprint_csv_file(assets_path + "/invalid-dataset-2.csv", "Invalid Dataset")
```

and the following dataset should pass validation with a warning,

```{python}
pprint_csv_file(assets_path + "/valid-dataset-2.csv", "Valid Dataset")
```

If the value cannot be coerced into a number, then an error should be logged as in the following dataset where "a" and "b" cannot be coerced into a number

```{python}
pprint_csv_file(assets_path + "/invalid-dataset-3.csv", "Invalid Dataset")
```

The ODM dictionary is currently written so that the defined maximum values are inclusive i.e. only values greater than the maximum values are invalid. All other values should pass this rule. For example, for the `geoLat` column and `geoLong` column, a value of 90 and 90.15 respectively would be considered valid as in the dataset below,

```{python}
# Using a yaml file here since in a CSV file every value is by default a string
pprint_yaml_file(assets_path + "/valid-dataset-3.yml")
```

## Error report

This rule can generate an error and/or a warning. 

An error is generated in the following cases:

1. The value is a number and is greater than the max value.
2. The value is not a number, can be coerced into one, and is greater than the max value.
3. The value is not a number and cannot be coerced into one.

The error report for the first two cases is shown below,

* **errorType**: greater_than_max_value
* **tableName** The name of the table with the invalid value
* **columnName**: The name of the column with the invalid value
* **rowNumber**: The index of the row with the invalid value
* **row**: The dictionary containing the invalid row
* **validationRuleFields**: The ODM data dictionary rows used to generate this rule
* **message**: Value \<invalid_value\> in row \<row_index\> in column \<column_name\> in table \<table_name\> is greater than the allowable maximum value of \<max_value\>

The error report for the third case is the identical except for the message field which is shown below,

* **message**: Value \<invalid_value\> in row \<row_index\> in column \<column_name\> in table \<table_name\> cannot be coerced into a number

A warning is generated when the value is a not a number but is coerced into one before validation. The warning report will have the following fields,

* **warningType**: greater_than_max_value
* **tableName** The name of the table with the invalid value
* **columnName**: The name of the column with the invalid value
* **rowNumber**: The index of the row with the invalid value
* **row**: The dictionary containing the invalid row
* **validationRuleFields**: The ODM data dictionary rows used to generate this rule
* **message**: Value \<invalid_value\> in row \<row_index\> in column \<column_name\> in table \<table_name\> is a \<invalid_type\> and was coerced into a number

The error reports for each of the invalid datasets above are shown above,

Invalid dataset 1

```{python}
pprint_json_file(assets_path + "/error-report-1.json")
```

Invalid dataset 2

```{python}
pprint_json_file(assets_path + "/error-report-2.json")
```

Invalid dataset 3

```{python}
pprint_json_file(assets_path + "/error-report-3.json")
```

Finally, for the valid coercable dataset (valid dataset 2) above, the following warning should be generated

```{python}
pprint_json_file(assets_path + "/error-report-4.json")
```

## Rule metadata

All the metadata for this rule is contained in the parts sheet in the data dictionary. The steps involved are:

1. [Get the table names in the dictionary](../specs/odm-how-tos.md#how-to-get-the-names-of-tables-that-are-part-of-the-odm)
1. [Get all the columns for each table](../specs/odm-how-tos.md#how-to-get-the-names-of-tables-that-are-part-of-the-odm)
2. Filter the rows to include only those columns whose data type is float or integer
    * The `dataType` column in the parts sheet contains this metadata
    * It has a number of possible values but we're looking for values of `float` or `integer`
3. Check whether the filtered rows has a maximum value. If it does then add the validation rule for that column.
    * The `maxValue` column contains this metadata
    * The possible values are a number or `NA`.
        * If the value is `NA` then this column does not have a maximum value.

For example in the following ODM dictionary snippet,

```{python}
pprint_csv_file(assets_path + "/parts-v2.csv", "Parts v2")
```

The `geoLat` part which is a column in the `sites` table has a `max` value of 90 and would have this rule set for it. On the other hand, the `geoEPSG` part which is also a column in the `sites` table would not have this rule due its `max` value being `NA`.

## Cerberus Schema

We can use the [maximum value validation](https://docs.python-cerberus.org/en/stable/validation-rules.html#min-max) rule in cerberus to implement this rule.

The generated cerberus object for the example above is shown below,

```{python}
pprint_yaml_file(assets_path + "/schema-v2.yml")
```

The metadata for this rule should include the row from the ODM for the part with its `partID` and `maxValue` column values.

## ODM Version 1

When generating the schema for version 1, we check whether the column has an [equivalent part in version 1](../specs/odm-how-tos.md#getting-the-version-1-equivalent-for-a-part). If it does, then we add it to the cerberus schema. For example,

```{python}
pprint_csv_file(assets_path + "/parts-v1.csv", "Parts v1")
```

The corresponding cerberus schema would be,

```{python}
pprint_yaml_file(assets_path + "/schema-v1.yml")
```

The metadata should include the following columns,

* The `partID` column value
* The `version1Location` column value
* The `version1Table` column value
* The `version1Variable` column value
* The `maxValue` column value
