{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "sys.path.append(\"../src\")\n",
        "\n",
        "# For importing YAML and CSV files\n",
        "from odm_validation.utils import import_dataset\n",
        "\n",
        "# Some pretty printing library and code\n",
        "from rich.pretty import pprint\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "def pprintDictList(dictList, title):\n",
        "    table = Table(title = title, expand = True)\n",
        "\n",
        "    dict_keys = dictList[0].keys()\n",
        "    for column_name in dict_keys:\n",
        "        table.add_column(column_name)\n",
        "\n",
        "    for current_dict in dictList:\n",
        "        row = []\n",
        "        for column_name in dict_keys:\n",
        "            row.append(current_dict[column_name])\n",
        "        table.add_row(*row)\n",
        "    \n",
        "    console = Console()\n",
        "    console.print(table)\n",
        "\n",
        "assets_path = \"../assets/validation-rules/duplicate-entries-found\""
      ],
      "id": "60b1cb14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# duplicate_entries_found\n",
        "\n",
        "This rule identifies when there are two identical entries with the same primary key. The rational has been described [here](https://odm.discourse.group/t/duplicate-entries-and-lastedited-field/55). In brief, the ODM can provide a papertrail of updates made to an entry by allowing users to update entries by: 1. Not deleting the old entry 2. Adding a new row for the updated entry and 3. Updating the `lastUpdated` field for the updated entry.\n",
        "\n",
        "For validation, this rule would be violated if two rows have the same primary key values but non-unique `lastUpdated` values. For example, the following ODM data snippet would fail validation.\n"
      ],
      "id": "8c7871b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "invalid_dataset = {\n",
        "    \"addresses\": import_dataset(assets_path + \"/invalid-dataset-1.csv\")\n",
        "}\n",
        "\n",
        "pprintDictList(invalid_dataset[\"addresses\"], \"Invalid Addresses Table\")"
      ],
      "id": "d3b6ff3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two rows (rows 1 and 2) with the same primary key value of `1` but also the same `lastUpdated` value.\n",
        "\n",
        "The following dataset would also fail validation,\n"
      ],
      "id": "ad3f0ecf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "invalid_dataset = {\n",
        "    \"addresses\": import_dataset(assets_path + \"/invalid-dataset-2.csv\")\n",
        "}\n",
        "\n",
        "pprintDictList(invalid_dataset[\"addresses\"], \"Invalid Addresses Table\")"
      ],
      "id": "5866cb63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following dataset would pass validation,\n"
      ],
      "id": "7f0fbe38"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "invalid_dataset = {\n",
        "    \"addresses\": import_dataset(assets_path + \"/valid-dataset.csv\")\n",
        "}\n",
        "\n",
        "pprintDictList(invalid_dataset[\"addresses\"], \"Valid Addresses Table\")"
      ],
      "id": "d08920d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error report\n",
        "\n",
        "The error report will have the following fields\n",
        "\n",
        "* **errorType**: duplicate_entries_found\n",
        "* **tableName**: The name of the table with duplicate entries\n",
        "* **columnName** The name of the primary key column\n",
        "* **rowNumbers**: The indexes of the duplicate entries\n",
        "* **rows** The entries in the table that failed this validation rule\n",
        "* **validationRuleFields**: The ODM data dictionary rule fields violated by this row\n",
        "* **message**: Duplicate entries found in rows <row_indexes> with primary key column <column_name> and primary key value <primary_key_value> in table <table_name>\n",
        "\n",
        "An example error report for the first invalid dataset shown above,\n",
        "\n",
        "```python\n",
        "[\n",
        "    {\n",
        "        \"errorType\": \"duplicate_entries_found\",\n",
        "        \"tableName\": \"addresses\",\n",
        "        \"columnName\": \"addId\",\n",
        "        \"rowNumbers\": [1,2],\n",
        "        \"rows\": [\n",
        "            {\n",
        "                \"addId\": \"1\",\n",
        "                \"lastUpdated\": \"\"\n",
        "            },\n",
        "            {\n",
        "                \"addId\": \"1\",\n",
        "                \"lastUpdated\": \"\"\n",
        "            }\n",
        "        ],\n",
        "        \"validationRuleFields\": [\n",
        "            {\n",
        "                \"partID\": \"addId\",\n",
        "                \"addresses\": \"pK\"\n",
        "            }\n",
        "        ],\n",
        "        \"message\": \"Duplicate entries found in rows 1,2 with primary key column addId and primary key value 1 in table addresses\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "In addition, a seperate error report object should be generated for each set of duplicate values found. For example for the following dataset,\n",
        "\n",
        "```python\n",
        "[\n",
        "    \"addresses\": [\n",
        "        {\n",
        "            \"addId\": \"1\",\n",
        "            \"lastUpdated\": \"\"\n",
        "        },\n",
        "        {\n",
        "            \"addId\": \"1\",\n",
        "            \"lastUpdated\": \"01/02/2023\"\n",
        "        },\n",
        "        {\n",
        "            \"addId\": \"1\",\n",
        "            \"lastUpdated\": \"01/02/2023\"\n",
        "        },\n",
        "        {\n",
        "            \"addId\": \"3\"\n",
        "        },\n",
        "        {\n",
        "            \"addId\": \"2\",\n",
        "            \"lastUpdated\": \"\"\n",
        "        },\n",
        "        {\n",
        "            \"addId\": \"2\",\n",
        "            \"lastUpdated\": \"\"\n",
        "        }\n",
        "    ]\n",
        "]\n",
        "```\n",
        "\n",
        "Two error report objects should be generated, one for rows 2 and 3 and one for rows 5 and 6.\n",
        "\n",
        "## Rule metadata\n",
        "\n",
        "All the metadata for this rule is contained in the parts sheet in the data dictionary. This rule should be added to the primary key column for all tables which can identified using these [instructions](../specs/odm-how-tos.md#how-to-get-the-columns-names-for-a-table).\n",
        "\n",
        "For example,\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"parts\": [\n",
        "        {\n",
        "            \"partID\": \"addId\",\n",
        "            \"addresses\": \"pK\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "Here the `addId` part can be identified as being the primary key for the addresses table and hence should have this rule implemented.\n",
        "\n",
        "## Cerberus Schema\n",
        "\n",
        "Cerberus currently does not have support for this rule. We will need to [extend the cerberus validator](https://docs.python-cerberus.org/en/stable/customize.html) to accomplish this.\n",
        "\n",
        "The generated cerberus object for the example above is shown below,\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"addresses\": {\n",
        "        \"type\": \"list\",\n",
        "        \"schema\": {\n",
        "            \"type\": \"dict\",\n",
        "            \"schema\": {\n",
        "                \"addId\": {\n",
        "                    \"noDuplicateEntries\": True,\n",
        "                    \"meta\": [\n",
        "                        {\n",
        "                            \"ruleId\": \"duplicate_entries_found\",\n",
        "                            \"meta\": [\n",
        "                                {\n",
        "                                    \"partID\": \"addId\",\n",
        "                                    \"addresses\": \"pK\"\n",
        "                                }\n",
        "                            ]\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "The metadata for this rule should include the row from the ODM that defines this part as a primary key.\n",
        "\n",
        "## ODM Version 1\n",
        "\n",
        "When generating the schema for version 1, we check whether the primary key column has a version 1 equivalent column. If it does, then we add to the cerberus schema. For example,\n",
        "\n",
        "```python\n",
        "[\n",
        "    {\n",
        "        \"partID\": \"addId\",\n",
        "        \"addresses\": \"pk\",\n",
        "        \"version1Location\": \"variables\",\n",
        "        \"version1Table\": \"Address\",\n",
        "        \"version1Variable\": \"AddressId\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "The corresponding cerberus schema would be,\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"Address\": {\n",
        "        \"type\": \"list\",\n",
        "        \"schema\": {\n",
        "            \"type\": \"dict\",\n",
        "            \"schema\": {\n",
        "                \"AddressId\": {\n",
        "                    \"noDuplicateEntries\": True,\n",
        "                    \"meta\": [\n",
        "                        {\n",
        "                            \"ruleId\": \"duplicate_entries_found\",\n",
        "                            \"meta\": [\n",
        "                                {\n",
        "                                    \"partID\": \"addId\",\n",
        "                                    \"addresses\": \"pk\",\n",
        "                                    \"version1Location\": \"variables\",\n",
        "                                    \"version1Table\": \"Address\",\n",
        "                                    \"version1Variable\": \"AddressId\"\n",
        "                                }\n",
        "                            ]\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "The metadata should include the following columns,\n",
        "\n",
        "* The `partID` column value\n",
        "* The <table_name> column value \n",
        "* The `version1Location` column value\n",
        "* The `version1Table` column value\n",
        "* The `version1Variable` column value"
      ],
      "id": "7bf2c7a2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}