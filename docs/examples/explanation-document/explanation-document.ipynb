{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting to know the validation library\n",
        "\n",
        "This document describes and demonstrates the main functions of the validation library. The document is a [quarto](https://quarto.org/) notebook which you can execute yourself.\n",
        "\n",
        "The library has two main functions:\n",
        "\n",
        "1. `validate_data`: to validate an ODM dataset using a validation schema.\n",
        "2. `generate_validation_schema`: to generate a validation schema from the ODM dictionary.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We'll walk through how to use these two functions, but first we will install the library dependencies by running the following command in the terminal. Make sure you are in the root of the library directory.\n",
        "\n",
        "`pip install -r requirements.txt`\n",
        "\n",
        "Next, the notebook uses the code to [rich](https://github.com/Textualize/rich) library to print and display tables. `rich` can be installed by running the following command in the terminal.\n",
        "\n",
        "`python -m pip install rich`\n"
      ],
      "id": "d33566b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import sys\n",
        "# Import the validation package. In the future you can install it using pip\n",
        "sys.path.append(\"../../../src\")\n",
        "\n",
        "# For importing YAML and CSV files\n",
        "from odm_validation.utils import import_schema, import_dataset\n",
        "\n",
        "# Some pretty printing library and code\n",
        "from rich.pretty import pprint\n",
        "from rich.table import Table\n",
        "from rich.console import Console\n",
        "def pprintDictList(dictList, title):\n",
        "    table = Table(title = title, expand = True)\n",
        "\n",
        "    dict_keys = dictList[0].keys()\n",
        "    for column_name in dict_keys:\n",
        "        table.add_column(column_name)\n",
        "\n",
        "    for current_dict in dictList:\n",
        "        row = []\n",
        "        for column_name in dict_keys:\n",
        "            row.append(current_dict[column_name])\n",
        "        table.add_row(*row)\n",
        "\n",
        "    console = Console()\n",
        "    console.print(table)"
      ],
      "id": "8dacde29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, install the two main library functions.\n"
      ],
      "id": "e29c0298"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from odm_validation.validation import validate_data, generate_validation_schema"
      ],
      "id": "86025d88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: validating a `sites` table with missing data\n",
        "\n",
        "Let's start by validating an ODM dataset. We will use just the `sites` table that \"contains information about a site; the location where an environmental sample was taken.\" The table has a number of columns, but we will validate just the `geoLat` and `geoLong` columns. These columns are mandatory in the `sites` table.\n",
        "\n",
        "Validating an ODM dataset requires a validation schema, which contains the rules to validate. For the demo we created a [YAML file](./validation-schemas/sites-schema.yml) which has the validation rules for the sites table. The next code chunk will import the validation schema.\n"
      ],
      "id": "a8f55f08"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "validation_schema = import_schema(\"./validation-schemas/sites-schema.yml\")\n",
        "\n",
        "pprint(validation_schema, expand_all=True)"
      ],
      "id": "964da46b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The validation schema has two fields:\n",
        "\n",
        "* `schemaVersion`: the version of the ODM the validation schema; and,\n",
        "* `schema`: which has the validation rules\n",
        "\n",
        "The structure of the validation rules follows a Python library called [cerberus](https://docs.python-cerberus.org/en/stable/schemas.html) that does all the validation heavy lifting. The PHES-ODM validation package integrates the ODM schema into cereberus and then uses cereberus methods to validate ODM data. \n",
        "\n",
        "The dataset in the next code chunk is a very simple `sites` table as a [CSV file](./datasets/invalid-sites-dataset.csv). The dataset has invalid data since it is missing the mandatory `geoLat` column. You can see in the above schema that `geolat` is mandatory by code `'geoLat': {'required': True}`.\n"
      ],
      "id": "694754be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "invalid_odm_dataset = {\n",
        "    \"sites\": import_dataset(\"./datasets/invalid-sites-dataset.csv\")\n",
        "}\n",
        "pprintDictList(invalid_odm_dataset[\"sites\"], \"Invalid ODM Dataset\")"
      ],
      "id": "6609b114",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consequentially, we get an error when we try to validate the dataset with our constructed validation schema.\n",
        "\n",
        "### `validate_data` function\n",
        "\n",
        "The `validate_data` function is used to validate ODM data. The function requires two pieces of information:\n",
        " 1. a validation schema;\n",
        " 1. an ODM dataset to validate. \n",
        " \n",
        " The function returns a validation report for the data. The following code chunk validates our invalid ODM dataset and prints the report.\n"
      ],
      "id": "d5cd1492"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "validation_result = validate_data(\n",
        "    validation_schema,\n",
        "    invalid_odm_dataset\n",
        ")\n",
        "\n",
        "pprint(validation_result)"
      ],
      "id": "eb66764a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding error messages\n",
        "\n",
        "Take a look at the `errors` field in the report. The report contains the list of errors in our dataset. Here we have two errors, each error says that we are missing the `geoLat` column.\n",
        "\n",
        "The error report provides metadata to trace which data row had invalid data. The `message` field is a human-readable description of the error. Although most of the fields are self-explanatory, if further clarification is needed, the `errorType` field can be used to dig deeper by finding the specification file for the validation rule. For example the `missing_mandatory_column` specification can be found in the [repo](../../validation-rules/missing_mandatory_column.md).\n",
        "\n",
        "The validation report also consists of versioning metadata fields to debug any errors in the ODM schema. These are the `data_version`, `schema_version`, and `package_version` fields.\n",
        "\n",
        "## Example: validating a validate data table\n",
        "\n",
        "For completeness let's validate a [valid dataset](./datasets/valid-sites-dataset.csv) in the next two code chunks.\n"
      ],
      "id": "9c3a611a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import a valid dataset\n",
        "valid_odm_data = {\n",
        "    \"sites\": import_dataset(\"./datasets/valid-sites-dataset.csv\")\n",
        "}\n",
        "\n",
        "pprintDictList(valid_odm_data[\"sites\"], \"Valid Sites Table\")"
      ],
      "id": "07a68242",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Validate the valid dataset\n",
        "pprint(\n",
        "    validate_data(validation_schema, valid_odm_data)\n",
        ")"
      ],
      "id": "cf621865",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the error list is empty.\n",
        "\n",
        "### `generate_validation_schema` function\n",
        "\n",
        "Generally, you don't need to create a validation schema because there are default OMD validation schemas for all ODM versions. However, you can create your own schema with the `generate_validation_schema` function. This function generates a validation schema from the ODM dictionary. The next chunk has a chunk from the [parts sheet](./dictionary/parts-v2.csv) in the dictionary.\n"
      ],
      "id": "87d5f33f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parts_sheet = import_dataset(\"./dictionary/parts-v2.csv\")\n",
        "\n",
        "pprintDictList(parts_sheet, 'Version 2 Parts Sheet')"
      ],
      "id": "239e8078",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above parts sheet describes,\n",
        "\n",
        "* A table called `sites`; and,\n",
        "* two mandatory columns in the `sites` table called `geoLat` and `geoLong`.\n",
        "\n",
        "We can use the `generate_validation_schema` function to generate a validation schema from the above parts sheet. The function takes two arguments;\n",
        "\n",
        "* the parts sheet as a list of Python dictionaries;\n",
        "* the ODM dictionary version we want for our generated schema.\n",
        "\n",
        "The next code chunk generates a validation schema from the above parts sheet for version 2.0.0 datasets.\n"
      ],
      "id": "fed4e163"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "validation_schema_2 = generate_validation_schema(parts_sheet, \"2.0.0\")\n",
        "\n",
        "pprint(validation_schema_2)"
      ],
      "id": "26bfbd01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we generated an identical validation schema as the one we manually created but with one main difference, it includes a `meta` field used to trace back to the row(s) in the parts sheet used to generate the validation rule.\n",
        "\n",
        "Validating our invalid dataset using the new validation schema returns the same error report as above, except for a new `validationRuleFields`, which is just a copy of the meta field. We can see that by running the next code.\n"
      ],
      "id": "6de9dd53"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pprint(validate_data(validation_schema_2, invalid_odm_dataset))"
      ],
      "id": "afd737f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validating different ODM versions\n",
        "\n",
        "We can also generate validation schemas for version 1.0.0 of the ODM dictionary. The next two code chunks import a [demo version 1 parts sheet](./dictionary/parts-v1.csv) and creates a validation schema.\n"
      ],
      "id": "6623150a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parts_sheet_v1 = import_dataset(\"./dictionary/parts-v1.csv\")\n",
        "\n",
        "pprintDictList(parts_sheet_v1, \"Version 1 Parts Sheet\")"
      ],
      "id": "01dac249",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "validation_schema_2_v1 = generate_validation_schema(parts_sheet_v1, \"1.0.0\")\n",
        "\n",
        "pprint(validation_schema_2_v1)"
      ],
      "id": "eabe6909",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The printed validation schema is once again identical to the previous one except, the table and column names have been replaced with their version 1 equivalents.\n",
        "\n",
        "Finally, the next two code chunks import an invalid [version 1 ODM dataset](./datasets/invalid-sites-dataset-v1.csv) and validates it using our version 1 validation schema.\n"
      ],
      "id": "b95ab91d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "version_one_invalid_odm_data = {\n",
        "    \"Site\": import_dataset(\"./datasets/invalid-sites-dataset-v1.csv\")\n",
        "}\n",
        "\n",
        "pprintDictList(version_one_invalid_odm_data[\"Site\"], \"Version 1 Sites Table\")"
      ],
      "id": "049d9a99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pprint(validate_data(validation_schema_2_v1, version_one_invalid_odm_data))"
      ],
      "id": "b702e1a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final points\n",
        "\n",
        "That's the end!\n",
        "\n",
        "Two final points:\n",
        "\n",
        "- the each ODM dictionary version has its validation schema;\n",
        "\n",
        "- the [validation-rules](../../validation-rules/) folder contains specifications for all the validation rules the library currently supports.\n",
        "\n",
        "May all your data validation reports contain only empty fields!"
      ],
      "id": "f0655a20"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}